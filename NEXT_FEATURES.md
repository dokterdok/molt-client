# NEXT_FEATURES.md - Feature Prioritization & Design

**Analysis Date:** 2025-01-28  
**Status:** Ready for implementation

---

## Executive Summary

Based on analysis of:
- âœ… **ROADMAP.md** â€” V1.0 must-haves and future plans
- âœ… **COMPETITIVE_ANALYSIS.md** â€” Gaps vs. ChatGPT/Claude desktop
- âœ… **Existing codebase** â€” Current implementation state
- âœ… **Testing infrastructure** â€” Vitest + Playwright already configured

**Key Findings:**
- **Strong foundation** â€” Core chat, streaming, encryption, search already solid
- **Clear V1.0 path** â€” 8 features block public release
- **3 quick wins** â€” High-impact features achievable in 1-2 days each
- **Autonomous testing** â€” Most features can be fully tested without human intervention

---

## 1. V1.0 Must-Haves Analysis

From ROADMAP.md, these features block public release:

### Critical (Blocking V1.0 Launch)

| Feature | Implementation Complexity | Testing Complexity | User Impact | Dependencies | Autonomous Testing |
|---------|--------------------------|-------------------|-------------|--------------|-------------------|
| **File Upload** | ğŸŸ¡ Medium (2-3 days) | ğŸŸ¢ Low | ğŸ”¥ Critical | Tauri fs plugin (âœ… installed) | âœ… Yes |
| **Image Rendering** | ğŸŸ¢ Low (4-6 hours) | ğŸŸ¢ Low | ğŸ”¥ High | None | âœ… Yes |
| **Regenerate Response** | ğŸŸ¢ Low (2-3 hours) | ğŸŸ¢ Low | ğŸ”¥ High | None | âœ… Yes |
| **Edit & Retry Messages** | ğŸŸ¡ Medium (1-2 days) | ğŸŸ¡ Medium | ğŸ”¥ High | None | âœ… Yes |
| **Export Conversations** | ğŸŸ¢ Low (4-6 hours) | ğŸŸ¢ Low | ğŸŸ¡ Medium | Tauri fs dialog (âœ… installed) | âœ… Yes |
| **Error Handling Polish** | ğŸŸ¢ Low (6-8 hours) | ğŸŸ¡ Medium | ğŸ”¥ High | None | âœ… Yes |
| **Auto-update System** | ğŸ”´ High (3-5 days) | ğŸ”´ High | ğŸŸ¡ Medium | GitHub releases, signing keys | âŒ No (needs release testing) |
| **Documentation** | ğŸŸ¢ Low (1 day) | ğŸŸ¢ Low | ğŸŸ¡ Medium | None | âœ… Yes (linting/formatting) |

### Nice-to-Have (V1.0)

| Feature | Implementation | Testing | Impact | Dependencies | Autonomous |
|---------|---------------|---------|--------|--------------|------------|
| **Keyboard Navigation** | ğŸŸ¡ Medium | ğŸŸ¢ Low | ğŸŸ¡ Medium | None | âœ… Yes |
| **Message Actions (Copy/Delete)** | ğŸŸ¢ Low | ğŸŸ¢ Low | ğŸŸ¡ Medium | None | âœ… Yes |
| **Conversation Organization** | ğŸŸ¡ Medium | ğŸŸ¡ Medium | ğŸŸ¡ Medium | None | âœ… Yes |
| **System Tray** | ğŸ”´ High | ğŸ”´ High | ğŸŸ¢ Low | OS-specific APIs | âŒ No |

---

## 2. Competitive Gaps Analysis

From COMPETITIVE_ANALYSIS.md, what ChatGPT/Claude have that Molt doesn't:

### High Priority Gaps

| Feature | ChatGPT | Claude | Molt | Feasibility | Strategic Value |
|---------|---------|--------|------|-------------|-----------------|
| **Edit previous messages** | âœ… | âœ… | âŒ | ğŸŸ¢ Easy | ğŸ”¥ Must-have |
| **Regenerate responses** | âœ… | âœ… | âŒ | ğŸŸ¢ Easy | ğŸ”¥ Must-have |
| **File upload (images)** | âœ… | âœ… | âŒ | ğŸŸ¡ Medium | ğŸ”¥ Must-have |
| **Export conversations** | âœ… | âœ… | âŒ | ğŸŸ¢ Easy | ğŸ”¥ High |
| **Global keyboard shortcut** | âœ… | âš ï¸ | âŒ | ğŸŸ¡ Medium | ğŸ”¥ High |
| **Folder/tag organization** | âŒ | âŒ | âŒ | ğŸŸ¡ Medium | ğŸ”¥ **Differentiator** |
| **Conversation branching** | âŒ | âŒ | âŒ | ğŸ”´ Hard | ğŸ”¥ **Differentiator** |
| **Voice input** | âœ… | âš ï¸ | âŒ | ğŸ”´ Hard | ğŸŸ¡ Medium |
| **Always-on-top mode** | âœ… | âš ï¸ | âŒ | ğŸŸ¢ Easy | ğŸŸ¡ Medium |

### What Molt Already Does Better

âœ… **Multi-model support** â€” Switch between GPT, Claude, Gemini (competitors lock to one provider)  
âœ… **Lighter weight** â€” Tauri vs Electron (~50MB vs ~500MB RAM)  
âœ… **Better context management** â€” Purpose-built for long conversations  
âœ… **Local-first** â€” No cloud dependency, full encryption at rest

---

## 3. Feature Prioritization Matrix

### Methodology

Each feature evaluated on:
- **Implementation complexity** â€” Hours/days to build
- **Testing complexity** â€” Can it be tested autonomously?
- **User impact** â€” High/medium/low demand
- **Dependencies** â€” Gateway changes? OS features?
- **Strategic value** â€” Does it differentiate Molt or match table stakes?

### Priority Tiers

#### ğŸ”¥ DO NOW (High Impact, Low Complexity, Autonomous Testing)

**1. Regenerate Response** â€” *2-3 hours*
- Implementation: ğŸŸ¢ Low (add button + re-send last user message)
- Testing: ğŸŸ¢ Low (Playwright E2E + Vitest component tests)
- User Impact: ğŸ”¥ Critical (table stakes, users expect this)
- Dependencies: None
- Autonomous: âœ… Yes

**2. Export Conversations** â€” *4-6 hours*
- Implementation: ğŸŸ¢ Low (Markdown/JSON export + Tauri file dialog)
- Testing: ğŸŸ¢ Low (verify file output format)
- User Impact: ğŸ”¥ High (frequently requested, sharing use case)
- Dependencies: Tauri fs plugin (âœ… already installed)
- Autonomous: âœ… Yes

**3. Image Rendering in Messages** â€” *4-6 hours*
- Implementation: ğŸŸ¢ Low (detect `![](url)` in markdown, render `<img>`)
- Testing: ğŸŸ¢ Low (snapshot tests with sample images)
- User Impact: ğŸ”¥ High (enables vision model responses)
- Dependencies: None (pure frontend)
- Autonomous: âœ… Yes

#### ğŸŸ¡ DO NEXT (High Impact, Medium Complexity)

**4. Edit & Retry Messages** â€” *1-2 days*
- Implementation: ğŸŸ¡ Medium (edit UI, conversation state branching)
- Testing: ğŸŸ¡ Medium (state mutations, edge cases)
- User Impact: ğŸ”¥ High (power users refine prompts)
- Dependencies: None
- Autonomous: âœ… Yes

**5. File Upload (Images/PDFs)** â€” *2-3 days*
- Implementation: ğŸŸ¡ Medium (Tauri fs read, base64 encode, send to Gateway)
- Testing: ğŸŸ¡ Medium (mock file system, test different formats)
- User Impact: ğŸ”¥ Critical (vision models, document analysis)
- Dependencies: Tauri fs plugin (âœ… installed), Gateway must support attachments
- Autonomous: âœ… Yes (mock files in tests)

**6. Enhanced Keyboard Navigation** â€” *1-2 days*
- Implementation: ğŸŸ¡ Medium (keyboard event handlers, focus management)
- Testing: ğŸŸ¢ Low (Playwright keyboard interaction tests)
- User Impact: ğŸŸ¡ Medium (power users love it)
- Dependencies: None
- Autonomous: âœ… Yes

**7. Message Copy/Delete Actions** â€” *6-8 hours*
- Implementation: ğŸŸ¢ Low (context menu or hover buttons)
- Testing: ğŸŸ¢ Low (click tests)
- User Impact: ğŸŸ¡ Medium (nice-to-have QoL)
- Dependencies: None
- Autonomous: âœ… Yes

**8. Conversation Organization (Folders/Sort)** â€” *2-3 days*
- Implementation: ğŸŸ¡ Medium (folder state, drag-drop, sort logic)
- Testing: ğŸŸ¡ Medium (state mutations, persistence)
- User Impact: ğŸ”¥ High (differentiator, competitors lack this)
- Dependencies: None (extend existing store + IndexedDB)
- Autonomous: âœ… Yes

#### ğŸŸ  PARK (Needs Human Testing or Gateway Changes)

**9. Auto-update System** â€” *3-5 days*
- Implementation: ğŸ”´ High (Tauri updater, GitHub releases, signing)
- Testing: ğŸ”´ High (must test on real OS environments)
- User Impact: ğŸŸ¡ Medium (important for distribution, not core UX)
- Dependencies: GitHub release workflow, code signing certs
- Autonomous: âŒ No (requires manual release testing)

**10. System Tray Integration** â€” *2-3 days*
- Implementation: ğŸ”´ High (OS-specific, Tauri tray API)
- Testing: ğŸ”´ High (must verify on Windows/Mac/Linux)
- User Impact: ğŸŸ¢ Low (nice-to-have, not essential)
- Dependencies: OS system tray APIs
- Autonomous: âŒ No (visual verification needed)

**11. Voice Input/Output** â€” *5-7 days*
- Implementation: ğŸ”´ High (audio recording, Whisper API, TTS playback)
- Testing: ğŸ”´ High (audio devices, permissions, playback)
- User Impact: ğŸŸ¡ Medium (growing demand, but not V1.0 critical)
- Dependencies: Audio APIs, Whisper/TTS backend
- Autonomous: âŒ No (audio quality testing)

**12. Conversation Branching** â€” *4-5 days*
- Implementation: ğŸ”´ High (conversation tree state, UI complexity)
- Testing: ğŸŸ¡ Medium (state logic testable, UI needs validation)
- User Impact: ğŸ”¥ High (differentiator, power user feature)
- Dependencies: None (pure frontend, but complex)
- Autonomous: âš ï¸ Partial (logic yes, UX needs human review)

#### â›” SKIP (Low Impact or Out of Scope for V1.0)

**Team Collaboration** â€” Different product, complex scope  
**Mobile Apps** â€” Tauri mobile still beta, desktop-first strategy  
**Plugin System** â€” V2.0 feature, needs architecture work  
**Browser Extension** â€” Different distribution channel  
**Multi-language UI** â€” Start English-only, localize later  
**AI Training/Fine-tuning** â€” Not core value prop

---

## 4. Top 3 "DO NOW" Features â€” Detailed Implementation Specs

These three features have:
- âœ… High user impact (critical or high demand)
- âœ… Low implementation complexity (hours, not days)
- âœ… Fully autonomous testing (no human verification needed)
- âœ… No external dependencies (pure frontend or existing plugins)

### Ship order: #1 â†’ #2 â†’ #3 (fastest wins first)

---

## Feature #1: Regenerate Response

### Overview
Allow users to regenerate the last assistant response without retyping their message. Standard feature in all AI chat apps.

### User Story
> "As a user, when I receive an unsatisfactory response, I want to regenerate it without retyping my prompt, so I can quickly get a better answer."

### Implementation Complexity
ğŸŸ¢ **Low** â€” 2-3 hours

### Testing Complexity
ğŸŸ¢ **Low** â€” Fully autonomous with Playwright + Vitest

### User Impact
ğŸ”¥ **Critical** â€” Table stakes feature, users expect this

---

### Detailed Implementation Spec

#### Files to Modify

**1. `src/stores/store.ts`** â€” Add regenerate action
```typescript
// Add to Store interface
interface Store {
  // ... existing
  regenerateLastResponse: (conversationId: string) => void;
}

// Add implementation
regenerateLastResponse: (conversationId: string) => {
  const conversation = get().conversations.find(c => c.id === conversationId);
  if (!conversation) return;

  // Find last user message
  const lastUserMessageIndex = conversation.messages
    .map((m, i) => ({ ...m, index: i }))
    .reverse()
    .find(m => m.role === 'user')?.index;

  if (lastUserMessageIndex === undefined) return;

  // Remove assistant message(s) after last user message
  const newMessages = conversation.messages.slice(0, lastUserMessageIndex + 1);
  
  // Update conversation
  set(state => ({
    conversations: state.conversations.map(c =>
      c.id === conversationId
        ? { ...c, messages: newMessages, updatedAt: new Date() }
        : c
    )
  }));

  // Persist
  updatePersistedConversation(conversationId, { messages: newMessages });

  // Re-send last user message (trigger in App.tsx via event)
  window.dispatchEvent(new CustomEvent('molt:regenerate', { 
    detail: { conversationId, message: conversation.messages[lastUserMessageIndex] }
  }));
}
```

**2. `src/components/MessageBubble.tsx`** â€” Add regenerate button
```typescript
// Add to MessageBubble props
interface MessageBubbleProps {
  // ... existing
  isLastAssistantMessage?: boolean;
  onRegenerate?: () => void;
}

// Add button in UI (only for last assistant message)
{isLastAssistantMessage && !isStreaming && (
  <button
    onClick={onRegenerate}
    className="mt-2 text-sm text-gray-500 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-200 flex items-center gap-1"
    aria-label="Regenerate response"
  >
    <RefreshCw className="w-4 h-4" />
    Regenerate
  </button>
)}
```

**3. `src/components/ChatView.tsx`** â€” Wire up regenerate logic
```typescript
// Detect last assistant message
const lastAssistantMessageIndex = conversation.messages
  .map((m, i) => ({ ...m, index: i }))
  .reverse()
  .find(m => m.role === 'assistant')?.index;

// Pass to MessageBubble
<MessageBubble
  message={msg}
  isLastAssistantMessage={i === lastAssistantMessageIndex}
  onRegenerate={() => regenerateLastResponse(conversation.id)}
/>

// Listen for regenerate event and re-send via WebSocket
useEffect(() => {
  const handleRegenerate = (e: CustomEvent) => {
    const { conversationId, message } = e.detail;
    if (conversationId === currentConversationId) {
      sendMessage(message.content); // existing send logic
    }
  };

  window.addEventListener('molt:regenerate', handleRegenerate);
  return () => window.removeEventListener('molt:regenerate', handleRegenerate);
}, [currentConversationId]);
```

**4. `src/App.tsx`** â€” No changes needed (WebSocket logic already handles re-sends)

---

### Acceptance Criteria

âœ… **AC1:** Regenerate button appears only on the last assistant message  
âœ… **AC2:** Clicking regenerate removes the assistant response  
âœ… **AC3:** Last user message is re-sent to the Gateway  
âœ… **AC4:** New response streams in and replaces the old one  
âœ… **AC5:** Regenerate button disappears during streaming  
âœ… **AC6:** Works correctly in conversations with multiple back-and-forth exchanges  
âœ… **AC7:** Persists correctly to IndexedDB after regeneration  
âœ… **AC8:** Keyboard shortcut: `Cmd/Ctrl+R` triggers regenerate (bonus)

---

### Test Plan

#### Unit Tests (`src/stores/store.test.ts`)

```typescript
describe('regenerateLastResponse', () => {
  it('should remove last assistant message', () => {
    const store = useStore.getState();
    const conv = store.createConversation();
    
    store.addMessage(conv.id, { role: 'user', content: 'Hello' });
    store.addMessage(conv.id, { role: 'assistant', content: 'Hi there!' });
    
    store.regenerateLastResponse(conv.id);
    
    const updated = store.conversations.find(c => c.id === conv.id);
    expect(updated.messages).toHaveLength(1);
    expect(updated.messages[0].role).toBe('user');
  });

  it('should dispatch regenerate event', () => {
    const eventSpy = vi.fn();
    window.addEventListener('molt:regenerate', eventSpy);
    
    const store = useStore.getState();
    const conv = store.createConversation();
    store.addMessage(conv.id, { role: 'user', content: 'Test' });
    store.addMessage(conv.id, { role: 'assistant', content: 'Response' });
    
    store.regenerateLastResponse(conv.id);
    
    expect(eventSpy).toHaveBeenCalled();
  });

  it('should handle no assistant messages gracefully', () => {
    const store = useStore.getState();
    const conv = store.createConversation();
    store.addMessage(conv.id, { role: 'user', content: 'Hello' });
    
    // Should not crash
    expect(() => store.regenerateLastResponse(conv.id)).not.toThrow();
  });
});
```

#### Component Tests (`src/components/MessageBubble.test.tsx`)

```typescript
it('should show regenerate button for last assistant message', () => {
  render(
    <MessageBubble
      message={{ role: 'assistant', content: 'Test', id: '1', timestamp: new Date() }}
      isLastAssistantMessage={true}
    />
  );
  
  expect(screen.getByLabelText('Regenerate response')).toBeInTheDocument();
});

it('should not show regenerate button for user messages', () => {
  render(
    <MessageBubble
      message={{ role: 'user', content: 'Test', id: '1', timestamp: new Date() }}
      isLastAssistantMessage={false}
    />
  );
  
  expect(screen.queryByLabelText('Regenerate response')).not.toBeInTheDocument();
});

it('should call onRegenerate when clicked', () => {
  const mockRegenerate = vi.fn();
  render(
    <MessageBubble
      message={{ role: 'assistant', content: 'Test', id: '1', timestamp: new Date() }}
      isLastAssistantMessage={true}
      onRegenerate={mockRegenerate}
    />
  );
  
  fireEvent.click(screen.getByLabelText('Regenerate response'));
  expect(mockRegenerate).toHaveBeenCalled();
});
```

#### E2E Tests (`e2e/regenerate.spec.ts`)

```typescript
import { test, expect } from '@playwright/test';

test.describe('Regenerate Response', () => {
  test('should regenerate last response', async ({ page }) => {
    await page.goto('http://localhost:1420');
    
    // Wait for app to load
    await page.waitForSelector('[data-testid="chat-input"]');
    
    // Send a message
    await page.fill('[data-testid="chat-input"]', 'Tell me a joke');
    await page.press('[data-testid="chat-input"]', 'Enter');
    
    // Wait for response
    await page.waitForSelector('[data-testid="message-assistant"]');
    const firstResponse = await page.textContent('[data-testid="message-assistant"]');
    
    // Click regenerate
    await page.click('[aria-label="Regenerate response"]');
    
    // Wait for new response
    await page.waitForSelector('[data-testid="message-assistant"]');
    const newResponse = await page.textContent('[data-testid="message-assistant"]');
    
    // Response should be different (or at least re-streamed)
    expect(newResponse).toBeTruthy();
  });

  test('should only show regenerate on last assistant message', async ({ page }) => {
    await page.goto('http://localhost:1420');
    
    // Send multiple messages
    await page.fill('[data-testid="chat-input"]', 'First message');
    await page.press('[data-testid="chat-input"]', 'Enter');
    await page.waitForSelector('[data-testid="message-assistant"]');
    
    await page.fill('[data-testid="chat-input"]', 'Second message');
    await page.press('[data-testid="chat-input"]', 'Enter');
    await page.waitForSelector('[data-testid="message-assistant"]:nth-of-type(2)');
    
    // Only last assistant message should have regenerate button
    const regenerateButtons = await page.$$('[aria-label="Regenerate response"]');
    expect(regenerateButtons).toHaveLength(1);
  });
});
```

---

### Edge Cases to Handle

âš ï¸ **Empty conversation** â€” Don't show regenerate if no messages  
âš ï¸ **User message only** â€” Don't show regenerate if no assistant response yet  
âš ï¸ **Streaming in progress** â€” Hide regenerate button during streaming  
âš ï¸ **Connection lost** â€” Show error if Gateway disconnected during regenerate  
âš ï¸ **Rapid clicks** â€” Debounce regenerate button to prevent double-sends

---

### Success Metrics

ğŸ“Š **Usage:** % of users who use regenerate in first week  
ğŸ“Š **Frequency:** Average regenerations per conversation  
ğŸ“Š **Error rate:** Regenerate failures due to connection issues

---

## Feature #2: Export Conversations

### Overview
Allow users to export conversations as Markdown or JSON files. Essential for sharing, archiving, and backup.

### User Story
> "As a user, I want to export my conversations so I can share insights with colleagues, archive important chats, or back up my data."

### Implementation Complexity
ğŸŸ¢ **Low** â€” 4-6 hours

### Testing Complexity
ğŸŸ¢ **Low** â€” Verify file content programmatically

### User Impact
ğŸ”¥ **High** â€” Frequently requested, enables sharing use case

---

### Detailed Implementation Spec

#### Files to Modify

**1. `src/lib/export.ts`** â€” New file for export logic
```typescript
import { Conversation } from '../stores/store';
import { save } from '@tauri-apps/plugin-dialog';
import { writeTextFile } from '@tauri-apps/plugin-fs';

/**
 * Export conversation to Markdown format
 */
export async function exportAsMarkdown(conversation: Conversation): Promise<void> {
  const markdown = conversationToMarkdown(conversation);
  
  const filePath = await save({
    defaultPath: `${sanitizeFilename(conversation.title)}.md`,
    filters: [{ name: 'Markdown', extensions: ['md'] }]
  });
  
  if (filePath) {
    await writeTextFile(filePath, markdown);
  }
}

/**
 * Export conversation to JSON format
 */
export async function exportAsJSON(conversation: Conversation): Promise<void> {
  const json = JSON.stringify(conversation, null, 2);
  
  const filePath = await save({
    defaultPath: `${sanitizeFilename(conversation.title)}.json`,
    filters: [{ name: 'JSON', extensions: ['json'] }]
  });
  
  if (filePath) {
    await writeTextFile(filePath, json);
  }
}

/**
 * Export conversation to plain text
 */
export async function exportAsText(conversation: Conversation): Promise<void> {
  const text = conversationToText(conversation);
  
  const filePath = await save({
    defaultPath: `${sanitizeFilename(conversation.title)}.txt`,
    filters: [{ name: 'Text', extensions: ['txt'] }]
  });
  
  if (filePath) {
    await writeTextFile(filePath, text);
  }
}

/**
 * Convert conversation to Markdown string
 */
function conversationToMarkdown(conversation: Conversation): string {
  const lines: string[] = [];
  
  // Header
  lines.push(`# ${conversation.title}`);
  lines.push('');
  lines.push(`**Created:** ${conversation.createdAt.toLocaleString()}`);
  lines.push(`**Updated:** ${conversation.updatedAt.toLocaleString()}`);
  if (conversation.model) {
    lines.push(`**Model:** ${conversation.model}`);
  }
  lines.push('');
  lines.push('---');
  lines.push('');
  
  // Messages
  conversation.messages.forEach((msg, i) => {
    const roleLabel = msg.role === 'user' ? 'ğŸ‘¤ **You**' : 'ğŸ¤– **Assistant**';
    const timestamp = msg.timestamp.toLocaleString();
    
    lines.push(`### ${roleLabel} Â· ${timestamp}`);
    lines.push('');
    lines.push(msg.content);
    lines.push('');
    
    // Thinking content if present
    if (msg.thinkingContent) {
      lines.push('<details>');
      lines.push('<summary>ğŸ’­ Thinking process</summary>');
      lines.push('');
      lines.push(msg.thinkingContent);
      lines.push('</details>');
      lines.push('');
    }
    
    // Model used
    if (msg.modelUsed) {
      lines.push(`*Model: ${msg.modelUsed}*`);
      lines.push('');
    }
    
    if (i < conversation.messages.length - 1) {
      lines.push('---');
      lines.push('');
    }
  });
  
  // Footer
  lines.push('');
  lines.push('---');
  lines.push('');
  lines.push(`*Exported from Molt on ${new Date().toLocaleString()}*`);
  
  return lines.join('\n');
}

/**
 * Convert conversation to plain text
 */
function conversationToText(conversation: Conversation): string {
  const lines: string[] = [];
  
  lines.push(conversation.title);
  lines.push('='.repeat(conversation.title.length));
  lines.push('');
  lines.push(`Created: ${conversation.createdAt.toLocaleString()}`);
  lines.push(`Updated: ${conversation.updatedAt.toLocaleString()}`);
  lines.push('');
  
  conversation.messages.forEach(msg => {
    const roleLabel = msg.role === 'user' ? 'You' : 'Assistant';
    lines.push(`[${msg.timestamp.toLocaleTimeString()}] ${roleLabel}:`);
    lines.push(msg.content);
    lines.push('');
  });
  
  lines.push(`--`);
  lines.push(`Exported from Molt on ${new Date().toLocaleString()}`);
  
  return lines.join('\n');
}

/**
 * Sanitize filename to remove invalid characters
 */
function sanitizeFilename(name: string): string {
  return name
    .replace(/[<>:"/\\|?*]/g, '-')
    .replace(/\s+/g, '_')
    .substring(0, 100);
}

/**
 * Copy conversation to clipboard as Markdown
 */
export async function copyToClipboard(conversation: Conversation): Promise<void> {
  const markdown = conversationToMarkdown(conversation);
  await navigator.clipboard.writeText(markdown);
}
```

**2. `src/components/Sidebar.tsx`** â€” Add export button to conversation context menu
```typescript
// Add to conversation right-click menu or three-dot menu
<DropdownMenuItem onClick={() => handleExport(conversation)}>
  <Download className="w-4 h-4 mr-2" />
  Export
</DropdownMenuItem>

// Export handler
const handleExport = async (conversation: Conversation) => {
  // Show export format dialog
  setExportDialogOpen(true);
  setConversationToExport(conversation);
};
```

**3. `src/components/ExportDialog.tsx`** â€” New dialog for export format selection
```typescript
import { Dialog, DialogContent, DialogHeader, DialogTitle } from './ui/dialog';
import { Button } from './ui/button';
import { Conversation } from '../stores/store';
import { exportAsMarkdown, exportAsJSON, exportAsText, copyToClipboard } from '../lib/export';
import { Download, Copy, FileText, FileJson, FileCode } from 'lucide-react';

interface ExportDialogProps {
  conversation: Conversation | null;
  open: boolean;
  onOpenChange: (open: boolean) => void;
}

export function ExportDialog({ conversation, open, onOpenChange }: ExportDialogProps) {
  if (!conversation) return null;

  const handleExport = async (format: 'markdown' | 'json' | 'text') => {
    try {
      switch (format) {
        case 'markdown':
          await exportAsMarkdown(conversation);
          break;
        case 'json':
          await exportAsJSON(conversation);
          break;
        case 'text':
          await exportAsText(conversation);
          break;
      }
      onOpenChange(false);
    } catch (err) {
      console.error('Export failed:', err);
      // Show error toast
    }
  };

  const handleCopy = async () => {
    try {
      await copyToClipboard(conversation);
      onOpenChange(false);
      // Show success toast
    } catch (err) {
      console.error('Copy failed:', err);
    }
  };

  return (
    <Dialog open={open} onOpenChange={onOpenChange}>
      <DialogContent>
        <DialogHeader>
          <DialogTitle>Export Conversation</DialogTitle>
        </DialogHeader>
        
        <div className="space-y-3">
          <Button
            variant="outline"
            className="w-full justify-start"
            onClick={() => handleExport('markdown')}
          >
            <FileText className="w-4 h-4 mr-2" />
            Markdown (.md)
            <span className="ml-auto text-xs text-gray-500">Best for sharing</span>
          </Button>
          
          <Button
            variant="outline"
            className="w-full justify-start"
            onClick={() => handleExport('json')}
          >
            <FileJson className="w-4 h-4 mr-2" />
            JSON (.json)
            <span className="ml-auto text-xs text-gray-500">Full metadata</span>
          </Button>
          
          <Button
            variant="outline"
            className="w-full justify-start"
            onClick={() => handleExport('text')}
          >
            <FileCode className="w-4 h-4 mr-2" />
            Plain Text (.txt)
            <span className="ml-auto text-xs text-gray-500">Simple format</span>
          </Button>
          
          <div className="border-t pt-3">
            <Button
              variant="outline"
              className="w-full justify-start"
              onClick={handleCopy}
            >
              <Copy className="w-4 h-4 mr-2" />
              Copy to Clipboard
            </Button>
          </div>
        </div>
      </DialogContent>
    </Dialog>
  );
}
```

**4. `src/components/ChatView.tsx`** â€” Add export button to chat header
```typescript
// Add to chat header toolbar
<Button
  variant="ghost"
  size="sm"
  onClick={() => setExportDialogOpen(true)}
  title="Export conversation"
>
  <Download className="w-4 h-4" />
</Button>

<ExportDialog
  conversation={conversation}
  open={exportDialogOpen}
  onOpenChange={setExportDialogOpen}
/>
```

---

### Acceptance Criteria

âœ… **AC1:** Export button appears in conversation context menu and chat header  
âœ… **AC2:** Export dialog offers Markdown, JSON, and Plain Text formats  
âœ… **AC3:** File save dialog opens with correct default filename  
âœ… **AC4:** Exported Markdown includes title, timestamps, messages, thinking content  
âœ… **AC5:** Exported JSON matches Conversation interface schema  
âœ… **AC6:** Copy to clipboard works without file dialog  
âœ… **AC7:** Filename sanitizes invalid characters (e.g., `/`, `:`, `<`, `>`)  
âœ… **AC8:** Export shows success toast on completion  
âœ… **AC9:** Export shows error toast on failure (e.g., permission denied)

---

### Test Plan

#### Unit Tests (`src/lib/export.test.ts`)

```typescript
import { describe, it, expect } from 'vitest';
import { conversationToMarkdown, conversationToText, sanitizeFilename } from './export';
import { Conversation } from '../stores/store';

describe('Export utilities', () => {
  const mockConversation: Conversation = {
    id: '1',
    title: 'Test Chat',
    messages: [
      { id: 'm1', role: 'user', content: 'Hello', timestamp: new Date('2025-01-28T10:00:00') },
      { id: 'm2', role: 'assistant', content: 'Hi there!', timestamp: new Date('2025-01-28T10:00:05'), modelUsed: 'claude-sonnet-4-5' }
    ],
    createdAt: new Date('2025-01-28T10:00:00'),
    updatedAt: new Date('2025-01-28T10:00:05'),
    thinkingEnabled: false,
    isPinned: false
  };

  it('should convert conversation to Markdown', () => {
    const markdown = conversationToMarkdown(mockConversation);
    
    expect(markdown).toContain('# Test Chat');
    expect(markdown).toContain('ğŸ‘¤ **You**');
    expect(markdown).toContain('ğŸ¤– **Assistant**');
    expect(markdown).toContain('Hello');
    expect(markdown).toContain('Hi there!');
    expect(markdown).toContain('Model: claude-sonnet-4-5');
  });

  it('should convert conversation to plain text', () => {
    const text = conversationToText(mockConversation);
    
    expect(text).toContain('Test Chat');
    expect(text).toContain('You:');
    expect(text).toContain('Assistant:');
    expect(text).toContain('Hello');
    expect(text).toContain('Hi there!');
  });

  it('should sanitize filenames', () => {
    expect(sanitizeFilename('Test/Chat:2025')).toBe('Test-Chat-2025');
    expect(sanitizeFilename('Test<>Chat')).toBe('Test--Chat');
    expect(sanitizeFilename('Test Chat')).toBe('Test_Chat');
  });

  it('should handle empty conversations', () => {
    const emptyConv: Conversation = {
      ...mockConversation,
      messages: []
    };
    
    const markdown = conversationToMarkdown(emptyConv);
    expect(markdown).toContain('# Test Chat');
  });

  it('should include thinking content in Markdown', () => {
    const convWithThinking: Conversation = {
      ...mockConversation,
      messages: [
        ...mockConversation.messages,
        {
          id: 'm3',
          role: 'assistant',
          content: 'Complex answer',
          timestamp: new Date(),
          thinkingContent: 'Let me think about this...'
        }
      ]
    };
    
    const markdown = conversationToMarkdown(convWithThinking);
    expect(markdown).toContain('ğŸ’­ Thinking process');
    expect(markdown).toContain('Let me think about this...');
  });
});
```

#### E2E Tests (`e2e/export.spec.ts`)

```typescript
import { test, expect } from '@playwright/test';
import fs from 'fs/promises';
import path from 'path';

test.describe('Export Conversations', () => {
  test('should export conversation as Markdown', async ({ page }) => {
    await page.goto('http://localhost:1420');
    
    // Create a conversation
    await page.fill('[data-testid="chat-input"]', 'Test message');
    await page.press('[data-testid="chat-input"]', 'Enter');
    await page.waitForSelector('[data-testid="message-assistant"]');
    
    // Open export dialog
    await page.click('[title="Export conversation"]');
    await page.waitForSelector('text=Export Conversation');
    
    // Mock file save dialog (in real app, this opens native dialog)
    // In tests, we can verify the export function was called
    await page.click('text=Markdown (.md)');
    
    // Verify export dialog closed
    await expect(page.locator('text=Export Conversation')).not.toBeVisible();
  });

  test('should copy conversation to clipboard', async ({ page, context }) => {
    // Grant clipboard permissions
    await context.grantPermissions(['clipboard-read', 'clipboard-write']);
    
    await page.goto('http://localhost:1420');
    
    // Create conversation
    await page.fill('[data-testid="chat-input"]', 'Clipboard test');
    await page.press('[data-testid="chat-input"]', 'Enter');
    await page.waitForSelector('[data-testid="message-assistant"]');
    
    // Export to clipboard
    await page.click('[title="Export conversation"]');
    await page.click('text=Copy to Clipboard');
    
    // Verify clipboard content
    const clipboardText = await page.evaluate(() => navigator.clipboard.readText());
    expect(clipboardText).toContain('Clipboard test');
    expect(clipboardText).toContain('ğŸ‘¤ **You**');
  });
});
```

---

### Edge Cases to Handle

âš ï¸ **Very long conversations** â€” Test with 100+ messages (performance)  
âš ï¸ **Special characters in title** â€” Ensure filename sanitization works  
âš ï¸ **Empty conversations** â€” Export should still work with header/footer  
âš ï¸ **Thinking content** â€” Include in Markdown, exclude from plain text  
âš ï¸ **Attachments** â€” Handle image/file attachments in export (future)  
âš ï¸ **Permission denied** â€” Graceful error if user can't write to location

---

### Success Metrics

ğŸ“Š **Usage:** % of users who export at least one conversation  
ğŸ“Š **Format preference:** Markdown vs JSON vs Text usage  
ğŸ“Š **Frequency:** Exports per user per week

---

## Feature #3: Image Rendering in Messages

### Overview
Render images inline in chat messages. Enables viewing AI-generated images and uploaded image attachments.

### User Story
> "As a user, when the AI sends an image URL or I upload an image, I want to see it rendered inline so I don't have to copy-paste URLs into a browser."

### Implementation Complexity
ğŸŸ¢ **Low** â€” 4-6 hours

### Testing Complexity
ğŸŸ¢ **Low** â€” Snapshot tests with sample images

### User Impact
ğŸ”¥ **High** â€” Essential for vision models and image generation

---

### Detailed Implementation Spec

#### Files to Modify

**1. `src/components/MessageBubble.tsx`** â€” Add image rendering logic
```typescript
import ReactMarkdown from 'react-markdown';
import rehypeHighlight from 'rehype-highlight';
import rehypeSanitize from 'rehype-sanitize';
import remarkGfm from 'remark-gfm';
import { ImageRenderer } from './ImageRenderer';

// Custom component for images
const components = {
  img: ImageRenderer,
  // ... existing code components
};

// In MessageBubble component
<ReactMarkdown
  remarkPlugins={[remarkGfm]}
  rehypePlugins={[rehypeHighlight, rehypeSanitize]}
  components={components}
>
  {message.content}
</ReactMarkdown>
```

**2. `src/components/ImageRenderer.tsx`** â€” New component for image handling
```typescript
import { useState } from 'react';
import { ZoomIn, ZoomOut, X, Download } from 'lucide-react';
import { cn } from '../lib/utils';

interface ImageRendererProps {
  src?: string;
  alt?: string;
  title?: string;
}

export function ImageRenderer({ src, alt, title }: ImageRendererProps) {
  const [isLoading, setIsLoading] = useState(true);
  const [hasError, setHasError] = useState(false);
  const [isLightboxOpen, setIsLightboxOpen] = useState(false);

  if (!src) {
    return <span className="text-red-500">âŒ Image source missing</span>;
  }

  const handleLoad = () => {
    setIsLoading(false);
  };

  const handleError = () => {
    setIsLoading(false);
    setHasError(true);
  };

  const handleDownload = async () => {
    try {
      const response = await fetch(src);
      const blob = await response.blob();
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = alt || 'image.png';
      a.click();
      URL.revokeObjectURL(url);
    } catch (err) {
      console.error('Download failed:', err);
    }
  };

  if (hasError) {
    return (
      <div className="border border-red-300 dark:border-red-700 rounded p-4 text-sm">
        <p className="text-red-600 dark:text-red-400">âŒ Failed to load image</p>
        {alt && <p className="text-gray-600 dark:text-gray-400 mt-1">{alt}</p>}
        <a
          href={src}
          target="_blank"
          rel="noopener noreferrer"
          className="text-blue-600 dark:text-blue-400 underline mt-2 inline-block"
        >
          Open in new tab
        </a>
      </div>
    );
  }

  return (
    <>
      <div className="relative inline-block max-w-full my-2">
        {/* Image */}
        <img
          src={src}
          alt={alt || 'Image'}
          title={title}
          className={cn(
            "max-w-full h-auto rounded-lg cursor-pointer transition-opacity",
            isLoading && "opacity-0"
          )}
          onLoad={handleLoad}
          onError={handleError}
          onClick={() => setIsLightboxOpen(true)}
          loading="lazy"
        />

        {/* Loading spinner */}
        {isLoading && (
          <div className="absolute inset-0 flex items-center justify-center">
            <div className="animate-spin rounded-full h-8 w-8 border-b-2 border-blue-500" />
          </div>
        )}

        {/* Hover overlay with actions */}
        {!isLoading && (
          <div className="absolute inset-0 bg-black/0 hover:bg-black/10 transition-colors rounded-lg group">
            <div className="absolute top-2 right-2 opacity-0 group-hover:opacity-100 transition-opacity flex gap-2">
              <button
                onClick={(e) => {
                  e.stopPropagation();
                  setIsLightboxOpen(true);
                }}
                className="p-2 bg-white/90 dark:bg-black/90 rounded-full hover:bg-white dark:hover:bg-black transition-colors"
                title="Zoom"
              >
                <ZoomIn className="w-4 h-4" />
              </button>
              <button
                onClick={(e) => {
                  e.stopPropagation();
                  handleDownload();
                }}
                className="p-2 bg-white/90 dark:bg-black/90 rounded-full hover:bg-white dark:hover:bg-black transition-colors"
                title="Download"
              >
                <Download className="w-4 h-4" />
              </button>
            </div>
          </div>
        )}
      </div>

      {/* Lightbox modal */}
      {isLightboxOpen && (
        <div
          className="fixed inset-0 z-50 bg-black/90 flex items-center justify-center p-4"
          onClick={() => setIsLightboxOpen(false)}
        >
          <button
            className="absolute top-4 right-4 p-2 bg-white/10 hover:bg-white/20 rounded-full transition-colors"
            onClick={() => setIsLightboxOpen(false)}
          >
            <X className="w-6 h-6 text-white" />
          </button>

          <img
            src={src}
            alt={alt || 'Image'}
            className="max-w-full max-h-full rounded-lg"
            onClick={(e) => e.stopPropagation()}
          />
        </div>
      )}
    </>
  );
}
```

**3. `src/stores/store.ts`** â€” Add image attachment support to Message interface
```typescript
// Already defined in the store:
export interface Attachment {
  id: string;
  filename: string;
  mimeType: string;
  data?: string; // base64
  url?: string;
}

// Message interface already has:
export interface Message {
  // ... existing fields
  attachments?: Attachment[];
}

// No code changes needed, just validate the interface is used
```

**4. `src/components/AttachmentRenderer.tsx`** â€” Render attachments in messages
```typescript
import { Attachment } from '../stores/store';
import { ImageRenderer } from './ImageRenderer';
import { FileText, File } from 'lucide-react';

interface AttachmentRendererProps {
  attachments: Attachment[];
}

export function AttachmentRenderer({ attachments }: AttachmentRendererProps) {
  if (!attachments || attachments.length === 0) return null;

  return (
    <div className="space-y-2 mt-2">
      {attachments.map(attachment => {
        // Image attachments
        if (attachment.mimeType.startsWith('image/')) {
          const src = attachment.url || `data:${attachment.mimeType};base64,${attachment.data}`;
          return (
            <ImageRenderer
              key={attachment.id}
              src={src}
              alt={attachment.filename}
            />
          );
        }

        // Non-image attachments (PDF, etc.)
        return (
          <div
            key={attachment.id}
            className="flex items-center gap-2 p-3 border rounded-lg bg-gray-50 dark:bg-gray-800"
          >
            {attachment.mimeType.includes('pdf') ? (
              <FileText className="w-5 h-5 text-red-500" />
            ) : (
              <File className="w-5 h-5 text-gray-500" />
            )}
            <span className="text-sm font-medium">{attachment.filename}</span>
            {attachment.url && (
              <a
                href={attachment.url}
                target="_blank"
                rel="noopener noreferrer"
                className="ml-auto text-blue-600 dark:text-blue-400 text-sm underline"
              >
                Open
              </a>
            )}
          </div>
        );
      })}
    </div>
  );
}
```

**5. Update `MessageBubble.tsx`** to render attachments
```typescript
import { AttachmentRenderer } from './AttachmentRenderer';

// In MessageBubble component, after markdown content:
{message.attachments && message.attachments.length > 0 && (
  <AttachmentRenderer attachments={message.attachments} />
)}
```

---

### Acceptance Criteria

âœ… **AC1:** Images in markdown (`![alt](url)`) render inline  
âœ… **AC2:** Base64 data URIs render correctly  
âœ… **AC3:** External URLs (https://) load and display  
âœ… **AC4:** Click image opens lightbox (fullscreen view)  
âœ… **AC5:** Lightbox has close button and click-outside-to-close  
âœ… **AC6:** Loading spinner shows while image loads  
âœ… **AC7:** Error state shows if image fails to load  
âœ… **AC8:** Hover shows zoom/download buttons  
âœ… **AC9:** Download button saves image to user's Downloads folder  
âœ… **AC10:** Images lazy-load (don't block initial render)  
âœ… **AC11:** Images respect max-width (don't overflow chat bubble)  
âœ… **AC12:** Works in both light and dark themes

---

### Test Plan

#### Component Tests (`src/components/ImageRenderer.test.tsx`)

```typescript
import { render, screen, fireEvent, waitFor } from '@testing-library/react';
import { ImageRenderer } from './ImageRenderer';

describe('ImageRenderer', () => {
  it('should render image with alt text', () => {
    render(<ImageRenderer src="https://example.com/image.png" alt="Test image" />);
    
    const img = screen.getByAltText('Test image');
    expect(img).toBeInTheDocument();
    expect(img).toHaveAttribute('src', 'https://example.com/image.png');
  });

  it('should show loading spinner initially', () => {
    render(<ImageRenderer src="https://example.com/image.png" />);
    
    // Image starts with opacity-0 while loading
    const img = screen.getByRole('img');
    expect(img).toHaveClass('opacity-0');
  });

  it('should open lightbox on click', async () => {
    render(<ImageRenderer src="https://example.com/image.png" alt="Test" />);
    
    const img = screen.getByAltText('Test');
    fireEvent.click(img);
    
    // Lightbox should appear
    await waitFor(() => {
      expect(screen.getAllByAltText('Test')).toHaveLength(2); // Original + lightbox
    });
  });

  it('should close lightbox on close button', async () => {
    render(<ImageRenderer src="https://example.com/image.png" alt="Test" />);
    
    // Open lightbox
    fireEvent.click(screen.getByAltText('Test'));
    
    // Close lightbox
    const closeButton = screen.getByRole('button');
    fireEvent.click(closeButton);
    
    await waitFor(() => {
      expect(screen.getAllByAltText('Test')).toHaveLength(1); // Only original
    });
  });

  it('should show error state on load failure', async () => {
    render(<ImageRenderer src="https://invalid-url.com/image.png" alt="Broken" />);
    
    const img = screen.getByAltText('Broken');
    fireEvent.error(img);
    
    await waitFor(() => {
      expect(screen.getByText(/Failed to load image/i)).toBeInTheDocument();
    });
  });

  it('should handle base64 data URIs', () => {
    const base64 = 'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==';
    render(<ImageRenderer src={base64} alt="Base64" />);
    
    const img = screen.getByAltText('Base64');
    expect(img).toHaveAttribute('src', base64);
  });
});
```

#### E2E Tests (`e2e/images.spec.ts`)

```typescript
import { test, expect } from '@playwright/test';

test.describe('Image Rendering', () => {
  test('should render images in markdown', async ({ page }) => {
    await page.goto('http://localhost:1420');
    
    // Simulate AI response with image
    // (In real app, this would come from Gateway)
    const markdownWithImage = 'Here is an image:\n\n![Test](https://via.placeholder.com/300)';
    
    // Mock the response (inject into store)
    await page.evaluate((md) => {
      const store = (window as any).__MOLT_STORE__;
      const conv = store.createConversation();
      store.addMessage(conv.id, { role: 'assistant', content: md });
    }, markdownWithImage);
    
    // Verify image rendered
    const img = page.locator('img[alt="Test"]');
    await expect(img).toBeVisible();
  });

  test('should open lightbox on image click', async ({ page }) => {
    await page.goto('http://localhost:1420');
    
    // Create message with image (similar to above)
    await page.evaluate(() => {
      const store = (window as any).__MOLT_STORE__;
      const conv = store.createConversation();
      store.addMessage(conv.id, {
        role: 'assistant',
        content: '![Test](https://via.placeholder.com/300)'
      });
    });
    
    // Click image
    await page.click('img[alt="Test"]');
    
    // Verify lightbox opened (z-50 fixed overlay)
    await expect(page.locator('.fixed.z-50')).toBeVisible();
  });

  test('should close lightbox with Escape key', async ({ page }) => {
    await page.goto('http://localhost:1420');
    
    // Open lightbox (same setup as above)
    await page.evaluate(() => {
      const store = (window as any).__MOLT_STORE__;
      const conv = store.createConversation();
      store.addMessage(conv.id, {
        role: 'assistant',
        content: '![Test](https://via.placeholder.com/300)'
      });
    });
    
    await page.click('img[alt="Test"]');
    await expect(page.locator('.fixed.z-50')).toBeVisible();
    
    // Press Escape
    await page.keyboard.press('Escape');
    
    // Lightbox should close
    await expect(page.locator('.fixed.z-50')).not.toBeVisible();
  });
});
```

---

### Edge Cases to Handle

âš ï¸ **Very large images** â€” Add max-height to prevent layout issues  
âš ï¸ **Broken image URLs** â€” Show error state with fallback link  
âš ï¸ **CORS issues** â€” Can't download cross-origin images  
âš ï¸ **Base64 extremely long** â€” Ensure doesn't crash renderer  
âš ï¸ **Multiple images in one message** â€” Should all render correctly  
âš ï¸ **Animated GIFs** â€” Should animate, not static  
âš ï¸ **SVG images** â€” Should render (but sanitize for XSS)

---

### Success Metrics

ğŸ“Š **Usage:** % of messages containing images  
ğŸ“Š **Lightbox usage:** % of images clicked to zoom  
ğŸ“Š **Load failures:** Error rate for image loading  
ğŸ“Š **Performance:** Time to render images (P95 < 500ms)

---

## 5. Implementation Order & Timeline

### Phase 1: Quick Wins (Week 1)
**Goal:** Ship 3 high-impact features in 1 week

| Day | Feature | Hours | Deliverable |
|-----|---------|-------|-------------|
| **Mon** | #1 Regenerate Response | 3h | Implementation complete |
| **Mon** | #1 Regenerate Response | 2h | Tests written & passing |
| **Tue** | #2 Export Conversations | 4h | Implementation complete |
| **Tue** | #2 Export Conversations | 2h | Tests written & passing |
| **Wed** | #3 Image Rendering | 4h | Implementation complete |
| **Wed** | #3 Image Rendering | 2h | Tests written & passing |
| **Thu** | Integration Testing | 4h | E2E tests, bug fixes |
| **Fri** | Polish & Documentation | 4h | Update docs, edge cases |

**Total:** ~25 hours (1 week of focused work)

### Phase 2: Medium Complexity (Week 2-3)
**Goal:** Ship edit messages, file upload, keyboard nav

- **Edit & Retry Messages** â€” 1-2 days
- **File Upload (Images)** â€” 2-3 days
- **Enhanced Keyboard Navigation** â€” 1-2 days
- **Message Copy/Delete** â€” 1 day

**Total:** ~7-9 days

### Phase 3: V1.0 Blockers (Week 4-5)
**Goal:** Address remaining V1.0 must-haves

- **Error Handling Polish** â€” 1 day
- **Documentation** â€” 1 day
- **Bug fixes & QA** â€” 3 days

**Total:** ~5 days

### Phase 4: Advanced Features (Post-V1.0)
**Goal:** Differentiation features

- **Conversation Organization** (folders/tags) â€” 2-3 days
- **Auto-update System** â€” 3-5 days (needs manual testing)
- **Conversation Branching** â€” 4-5 days

---

## 6. Risk Assessment

### Low Risk âœ…
- Regenerate response â€” Straightforward, existing patterns
- Export conversations â€” File I/O well-documented
- Image rendering â€” Standard markdown feature

### Medium Risk âš ï¸
- Edit messages â€” State mutations could introduce bugs
- File upload â€” File system permissions, encoding issues
- Keyboard navigation â€” Browser compatibility, focus management

### High Risk ğŸ”´
- Auto-update â€” Code signing, release infrastructure
- System tray â€” OS-specific, hard to test
- Voice I/O â€” Audio device access, quality issues

---

## 7. Dependencies & Blockers

### No Blockers (Ready to Start)
âœ… Regenerate response  
âœ… Export conversations  
âœ… Image rendering  
âœ… Message copy/delete  
âœ… Keyboard navigation

### Minor Dependencies (Plugins Installed)
âš ï¸ File upload â€” Tauri fs plugin (âœ… already in package.json)  
âš ï¸ Export file dialog â€” Tauri dialog plugin (âœ… already in package.json)

### Major Dependencies (Need Setup)
ğŸ”´ Auto-update â€” GitHub Actions, code signing certificates  
ğŸ”´ System tray â€” OS-specific testing environments  
ğŸ”´ Voice â€” Audio backend (Whisper API, TTS service)

---

## 8. Testing Strategy

### Unit Tests (Vitest)
- **Store actions** â€” State mutations, persistence
- **Utilities** â€” Export formatting, sanitization
- **Components** â€” Isolated UI logic

### Component Tests (React Testing Library)
- **User interactions** â€” Clicks, keyboard input
- **Conditional rendering** â€” Error states, loading states
- **Props validation** â€” Edge cases

### E2E Tests (Playwright)
- **User flows** â€” Full journeys (send message â†’ regenerate â†’ export)
- **Integration** â€” Components working together
- **Visual regression** â€” Screenshot comparison (optional)

### Coverage Goals
- **Critical paths** â€” 90%+ coverage (chat, persistence, encryption)
- **UI components** â€” 70%+ coverage
- **Utilities** â€” 80%+ coverage

---

## 9. Success Criteria for V1.0 Launch

### Feature Completeness
âœ… All "DO NOW" features shipped  
âœ… All "DO NEXT" features shipped (except branching)  
âœ… Error handling polished  
âœ… Documentation complete

### Quality Metrics
âœ… Test coverage >70%  
âœ… E2E tests cover critical flows  
âœ… No P0/P1 bugs in backlog  
âœ… Performance: Cold start <2s, message render <100ms

### User Readiness
âœ… User guide published  
âœ… Troubleshooting docs complete  
âœ… GitHub releases configured  
âœ… Privacy policy published

---

## 10. Next Steps

### Immediate Actions (This Week)
1. âœ… Review this document with main agent
2. â­ï¸ Implement Feature #1 (Regenerate Response)
3. â­ï¸ Write tests for Feature #1
4. â­ï¸ Ship to `main` branch
5. â­ï¸ Repeat for Features #2 and #3

### Questions for Main Agent
- **Prioritization:** Agree with DO NOW â†’ DO NEXT order?
- **Timeline:** Is 1 week for Phase 1 realistic?
- **Testing:** Should we add visual regression tests (Percy/Chromatic)?
- **Gateway:** Does current Gateway support file attachments? (For Feature #5)
- **Auto-update:** Do we have code signing certs? (For Phase 3)

---

## Appendix A: Feature Scoring Matrix

| Feature | Implementation | Testing | Impact | Dependencies | Score |
|---------|---------------|---------|--------|--------------|-------|
| Regenerate Response | 2h | ğŸŸ¢ | ğŸ”¥ | None | **9.5** |
| Export Conversations | 6h | ğŸŸ¢ | ğŸ”¥ | Tauri âœ… | **9.0** |
| Image Rendering | 6h | ğŸŸ¢ | ğŸ”¥ | None | **9.0** |
| Message Copy/Delete | 8h | ğŸŸ¢ | ğŸŸ¡ | None | **7.5** |
| Edit Messages | 16h | ğŸŸ¡ | ğŸ”¥ | None | **8.5** |
| File Upload | 24h | ğŸŸ¡ | ğŸ”¥ | Tauri âœ… | **8.0** |
| Keyboard Nav | 16h | ğŸŸ¢ | ğŸŸ¡ | None | **7.0** |
| Conversation Org | 24h | ğŸŸ¡ | ğŸ”¥ | None | **8.0** |
| Auto-update | 40h | ğŸ”´ | ğŸŸ¡ | Infra | **5.0** |
| System Tray | 24h | ğŸ”´ | ğŸŸ¢ | OS APIs | **4.0** |
| Voice I/O | 56h | ğŸ”´ | ğŸŸ¡ | Backend | **4.5** |
| Branching | 40h | ğŸŸ¡ | ğŸ”¥ | None | **7.0** |

**Scoring formula:**  
`Score = (Impact Ã— 3) + (10 - Implementation hrs / 4) + (Testing complexity bonus) - (Dependency penalty)`

Higher score = higher priority

---

## Appendix B: Competitor Feature Parity Checklist

### Table Stakes (Must Match)
- [x] Real-time streaming
- [x] Conversation history
- [x] Search
- [x] Model selection
- [ ] **Regenerate response** â† Feature #1
- [ ] **Edit messages** â† Feature #4
- [ ] **File upload** â† Feature #5
- [ ] **Export** â† Feature #2
- [x] Dark mode
- [x] Keyboard shortcuts (basic)

### Differentiation (Better Than Competitors)
- [x] Multi-model support âœ¨
- [x] Lightweight (Tauri) âœ¨
- [x] Better encryption âœ¨
- [ ] **Folders/tags** â† Feature #8 âœ¨
- [ ] **Conversation branching** â† Parked âœ¨
- [x] Local-first âœ¨

### Nice-to-Have (Post-V1.0)
- [ ] Voice input/output
- [ ] System tray
- [ ] Always-on-top
- [ ] Mobile apps
- [ ] Plugin system

---

**End of NEXT_FEATURES.md**

*This document is a living plan. Update as priorities shift, new features are proposed, or technical constraints change.*
